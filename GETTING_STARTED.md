
# Outline to use Vilio for your own project

This outline aims to explain how you can use the repo for your own Vision & Language problem. Be it Visual Question Answering, Visual Reasoning, Classification etc. 
For applying it to the Hateful Memes Dataset, refer to SCORE_REPRO.md. 
<br>
If anything pops up, do feel free to: Drop an issue / send a PR / send me an email at n.muennighoff@gmail.com

## Data

### Image-extraction

Extracting important features from images before training is the current standard in VL, as it significantly speeds up things. If you don't have extracted featurs yet, you can use the subrepo `vilio/py-bottom-up-attention/data`.
Place a folder named `img` with all your images into `vilio/py-bottom-up-attention/data`.

- Clone the repo: <br>
`git clone https://github.com/Muennighoff/vilio.git`
- Setup extraction: <br>
`cd vilio/py-bottom-up-attention; pip install -r requirements.txt` <br>
`pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'` <br>
`cd vilio/py-bottom-up-attention; python setup.py build develop` <br>

Then run feature extraction as follows:
`cd vilio/py-bottom-up-attention; python detectron2_mscoco_proposal_maxnms.py --batchsize 4 --split img --weight vgattr --minboxes 36 --maxboxes 36` <br>
I recommend leaving the parameters as is. Increasing the amount of boxes (hence features extracted) sometimes helps marginally, but will slow down extraction, training & inference significantly. <br>
Refer to the README.md under `vilio/py-bottom-up-attention/README.md` if you run into any problems.

### Using the image & text features

The repo provides code for dealing with .tsv features (which are generated by the extraction above) or .lmdb features. <br>

Depending on your feature format and text format, you probably want to go through either the code under `vilio/fts_lmdb/` or `vilio/fts_tsv/`. I recommend just copying the `hm_data.py` in either of these folders and adjusting the code for your file format & data columns. You can also adjust `hm_pretrain_data.py` if you plan to perform task-specific pretraining (Refer to the table at the end of this .md to see which model has task-specific pretraining - Note that all models are pretrained models, but it sometimes helps performing additional pre-training (masking etc) on your specific dataset). 

## Modeling

Once your data is ready, I'd recommend making a copy of `vilio/hm.py` and depending on your project consider the following adjustments:
- The score metric (currently roc-auc & accuracy)
- Remove/adjust the `clean_data` call, which is specific to the hm dataset
- Adjust the result dumping (currently dump_csv for a csv file output with id, predicted label, predicted probability)

Finally it is time to choose the model you want to run. Refer to the below table for a rough performance & implementation guide. 
Note that the performance rank might be very different for other datasets than Hateful Memes.
<br>

| Model | Language Transformer | Performance Rank for HM | Task-specific pre-training enabled |
|-|-|
| [E - ERNIE-VIL](https://arxiv.org/abs/2006.16934) | Full API documentation and tutorials |
| [D - DeVLBERT](https://arxiv.org/abs/2008.06884) | Tasks supported by ðŸ¤— Transformers |
| [O - OSCAR](https://arxiv.org/abs/2004.06165) | Using the `Tokenizer` class to prepare data for the models |
| [U - UNITER](https://arxiv.org/abs/1909.11740) | Using the models provided by ðŸ¤— Transformers in a PyTorch/TensorFlow training loop and the `Trainer` API |
| [V - VisualBERT](https://arxiv.org/abs/1908.03557) | Example scripts for fine-tuning models on a wide range of tasks |
| [X - LXMERT](https://arxiv.org/abs/1908.07490) | Upload and share your fine-tuned models with the community |
| [Migration](https://huggingface.co/transformers/migration.html) | Migrate to ðŸ¤— Transformers from `pytorch-transformers` or `pytorch-pretrained-bert` |


Now just run your adjusted version of `vilio/hm.py` with e.g. `python hm.py --model U --train train --valid dev_seen --test dev_seen --lr 1e-5 --batchSize 8 --tr bert-large-cased --epochs 5 --tsv --num_features 50 --loadpre ./data/uniter-large.pt --num_pos 6 --contrib --exp U50`. The parameters are explained at `vilio/params.py`.





